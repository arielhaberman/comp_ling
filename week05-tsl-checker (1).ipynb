{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSL data helper\n",
    "\n",
    "Let's examine a student's data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:\t n\n",
      "T:\t ['C', 'V', 'c', 'l', 'v']\n",
      "G:\t [('C', 'C'), ('C', 'l'), ('V', 'V'), ('V', 'l'), ('V', 'v'), ('l', 'C'), ('l', 'l'), ('l', '<'), ('v', 'C'), ('v', 'V'), ('v', 'v'), ('>', 'C'), ('>', 'V'), ('>', 'l'), ('>', 'v')]\n"
     ]
    }
   ],
   "source": [
    "import sigmapie\n",
    "nawuri = sigmapie.TSL(polar=\"n\")\n",
    "\n",
    "'''\n",
    "C = rounded consonant\n",
    "c = unrounded non-labial consonant\n",
    "l = unrounded labial consonant\n",
    "v = unrounded vowel\n",
    "V = rounded vowel\n",
    "'''\n",
    "\n",
    "data = ['cvlv', 'cvcvlv', 'cVcV', 'cvcv', 'cvcvcv', 'cVcV', \n",
    "        'cVCv', 'cVCVcC', 'cvlV', \n",
    "        'cvlVcV', 'cvlV', 'cvccv', 'cvcccv', 'cvclV', 'cvlcV', \n",
    "        'cvclv', 'cvlcv', 'cVcCv', 'cVCcv', 'cc', 'ccc', 'c', '']\n",
    "# data = ['cvcv', 'cVcV','cVCv', 'cVCVcC', 'cvccv', 'cVCcv', #non-blocked patterns\n",
    "#              'cvlcV', 'cvclv', 'cvlV', #blocked patterns\n",
    "#               'c', '']#other\n",
    "\n",
    "\n",
    "nawuri.data = data\n",
    "nawuri.extract_alphabet()\n",
    "nawuri.learn()\n",
    "#nawuri.switch_polarity()\n",
    "\n",
    "print(\"p:\\t\",nawuri.check_polarity())\n",
    "print(\"T:\\t\",nawuri.tier)\n",
    "print(\"G:\\t\",nawuri.grammar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: According to Jardine 2016, `c` should be removed from the tier because it is in free distribution\n",
    "\n",
    "***Actual* problem**: The `sigmapie` package implements a slightly different version of the TSL learning algorithm ([Jardine & McMullin 2016](https://adamjardine.net/files/jardinemcmullin2016tslk.pdf)), with stricter requirements on what can be removed from a tier (oops!)\n",
    "\n",
    "## TSL data helper\n",
    "\n",
    "The following functions test the first round of the learning algorithm (where $T = \\Sigma$) to see what can be removed from the tier. This is the same thing `sigmapie` does, but the below prints what it finds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fac(s, k):\n",
    "    '''get k-factors with edge markers'''\n",
    "    fac = []\n",
    "    s = '>'+s+'<'\n",
    "    if len(s) < k:\n",
    "        fac.append(tuple(s))\n",
    "    else:\n",
    "        for i in range(len(s)-(k-1)):\n",
    "            fac.append(tuple(s[i:i+k]))\n",
    "    return fac\n",
    "\n",
    "def sample_factors(sample, k):\n",
    "    '''get all k-factors from a data set'''\n",
    "    factors = []\n",
    "    for s in sample:\n",
    "        factors.extend(k_fac(s,k))\n",
    "    return factors\n",
    "\n",
    "def inject(fac,sym):\n",
    "    '''helper for Condition a for Theorem 2'''\n",
    "    injected = []\n",
    "    for i in range(len(fac)+1):\n",
    "        new = fac[:i] + (sym,) + fac[i:]\n",
    "        injected.append(new)\n",
    "    return [f for f in injected if f[0] != '<' and f[1] != '>']\n",
    "\n",
    "def eject(fac,sym):\n",
    "    '''helper for Condition b for Theorem 2'''\n",
    "    if sym in fac:\n",
    "        for i in range(len(f)):\n",
    "            if f[i] == 'a':\n",
    "                new = f[:i] + f[i+1:]\n",
    "                return new\n",
    "    \n",
    "def test_injections(less,kf,sym):\n",
    "    '''Tests condition a for Theorem 2'''\n",
    "    test_set = set()\n",
    "    for f in less:\n",
    "        for new in inject(f,sym):\n",
    "            test_set.add(new)\n",
    "    return test_set.difference(kf)\n",
    "\n",
    "def test_ejections(more,kf,sym):\n",
    "    '''Tests condition b for Theorem 2'''\n",
    "    test_set = set()\n",
    "    for f in more:\n",
    "        if sym in f:\n",
    "            for i in range(len(f)):\n",
    "                if f[i] == sym:\n",
    "                    new = f[:i] + f[i+1:]\n",
    "                    test_set.add(new)\n",
    "    return test_set.difference(kf)\n",
    "\n",
    "def test_sample_set(sample, k):\n",
    "    alphabet = list(set(list(''.join(sample))))\n",
    "    k_factors = sample_factors(sample, k)\n",
    "    less_factors = sample_factors(sample, k-1)\n",
    "    more_factors = sample_factors(sample, k+1)\n",
    "    for sym in alphabet:\n",
    "        print(f\"Testing distribution of '{sym}'...\", end =\"\")\n",
    "        i_result = test_injections(less_factors, k_factors, sym)\n",
    "        e_result = test_ejections(more_factors, k_factors, sym)\n",
    "        results = i_result.union(e_result)\n",
    "        if results == set():\n",
    "            print(f\"PASS, '{sym}' will be removed from T\")\n",
    "        else:\n",
    "            print(f\"FAIL\")\n",
    "            if i_result != set():\n",
    "                print(f\"\\t '{sym}' not freely distributed, missing factor(s) {i_result}\")\n",
    "            if e_result != set():\n",
    "                print(f\"\\t '{sym}' as an intervener has the following dependent factor(s): {e_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 - (NoMoreThan)OneB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing distribution of 'a'...PASS, 'a' will be removed from T\n",
      "Testing distribution of 'b'...FAIL\n",
      "\t 'b' not freely distributed, missing factor(s) {('b', 'b')}\n"
     ]
    }
   ],
   "source": [
    "alphabet = ['a','b']\n",
    "sample = ['','a','ba','ab','aba','aa']\n",
    "k = 2\n",
    "\n",
    "test_sample_set(sample, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:\t n\n",
      "T:\t ['b']\n",
      "G:\t [('b', 'b')]\n"
     ]
    }
   ],
   "source": [
    "oneb = sigmapie.TSL(polar=\"n\")\n",
    "oneb.data = sample\n",
    "oneb.extract_alphabet()\n",
    "oneb.learn()\n",
    "\n",
    "print(\"p:\\t\",oneb.check_polarity())\n",
    "print(\"T:\\t\",oneb.tier)\n",
    "print(\"G:\\t\",oneb.grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 - back to Nawuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cvlv', 'cvcvlv', 'cVcV', 'cvcv', 'cvcvcv', 'cVcV', 'cVCv', 'cVCVcC', 'cvlV', 'cvlVcV', 'cvlV', 'cvccv', 'cvcccv', 'cvclV', 'cvlcV', 'cvclv', 'cvlcv', 'cVcCv', 'cVCcv', 'cc', 'ccc', 'c', ''] \n",
      "\n",
      "Testing distribution of 'l'...FAIL\n",
      "\t 'l' not freely distributed, missing factor(s) {('l', 'C'), ('C', 'l')}\n",
      "\t 'l' as an intervener has the following dependent factor(s): {('v', 'V'), ('V', 'v')}\n",
      "Testing distribution of 'c'...PASS, 'c' will be removed from T\n",
      "Testing distribution of 'C'...FAIL\n",
      "\t 'C' not freely distributed, missing factor(s) {('C', 'C'), ('v', 'C'), ('C', 'l'), ('>', 'C'), ('l', 'C')}\n",
      "\t 'C' as an intervener has the following dependent factor(s): {('V', 'v')}\n",
      "Testing distribution of 'V'...FAIL\n",
      "\t 'V' not freely distributed, missing factor(s) {('v', 'V'), ('V', 'v')}\n",
      "Testing distribution of 'v'...FAIL\n",
      "\t 'v' not freely distributed, missing factor(s) {('v', 'V'), ('V', 'v'), ('v', 'C')}\n"
     ]
    }
   ],
   "source": [
    "print(data,\"\\n\")\n",
    "\n",
    "data += ['v', 'V', 'vv', 'VV', 'Vlv', 'l', 'll']\n",
    "\n",
    "test_sample_set(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:\t n\n",
      "T:\t ['C', 'V', 'l', 'v']\n",
      "G:\t [('C', 'C'), ('C', 'l'), ('V', 'v'), ('l', 'C'), ('v', 'C'), ('v', 'V'), ('>', 'C')]\n"
     ]
    }
   ],
   "source": [
    "new = sigmapie.TSL(polar=\"n\")\n",
    "new.data = data\n",
    "new.extract_alphabet()\n",
    "new.learn()\n",
    "\n",
    "print(\"p:\\t\",new.check_polarity())\n",
    "print(\"T:\\t\",new.tier)\n",
    "print(\"G:\\t\",new.grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One problem at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:\t ['V']\n",
      "G:\t [('>', '<'), ('V', 'V')]\n"
     ]
    }
   ],
   "source": [
    "stress_alpha = ['c','v','V']\n",
    "\n",
    "# V = stressed vowel\n",
    "# words must have exactly one stressed vowel\n",
    "\n",
    "stress_lang = sigmapie.TSL(polar=\"n\")\n",
    "stress_lang.tier = ['V']\n",
    "stress_lang.grammar = [('>', '<'),('V','V')]\n",
    "stress_lang.alphabet = stress_alpha\n",
    "\n",
    "print(\"T:\\t\",stress_lang.tier)\n",
    "print(\"G:\\t\",stress_lang.grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vVcv', 'vvcVcc', 'cVv', 'cvV', 'cvcV', 'vvVcc', 'vvVc', 'vVv', 'cV', 'cVc']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_lang.generate_sample(10,repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\t [('v', 'c'), ('V', '<'), ('V', 'c'), ('c', 'V'), ('>', 'c'), ('>', '<'), ('c', 'v'), ('v', '<')]\n"
     ]
    }
   ],
   "source": [
    "# syllables must always have one onset and no codas\n",
    "\n",
    "syl_sample = ['cV','cv','cvcv','cVcV','']\n",
    "syl_lang = sigmapie.SL(polar=\"p\")\n",
    "syl_lang.data = syl_sample\n",
    "syl_lang.extract_alphabet()\n",
    "syl_lang.learn()\n",
    "\n",
    "print(\"G:\\t\",syl_lang.grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'cvcvcV',\n",
       " 'cv',\n",
       " 'cVcV',\n",
       " 'cVcVcV',\n",
       " 'cvcV',\n",
       " 'cVcvcvcVcvcVcvcVcvcvcVcvcv',\n",
       " 'cvcVcv',\n",
       " 'cVcv',\n",
       " 'cV']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syl_lang.generate_sample(10,repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvcVcv', 'cvcV', 'cVcv', 'cV'}\n"
     ]
    }
   ],
   "source": [
    "# intersect the two languages\n",
    "# what is the complexity of this resulting language?\n",
    "\n",
    "stress_set = set(stress_lang.generate_sample(100,repeat=False))\n",
    "syl_set = set(syl_lang.generate_sample(100,repeat=False))\n",
    "\n",
    "print(stress_set.intersection(syl_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
